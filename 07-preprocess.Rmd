---
title: "06. Preprocessing chemical descriptors"
author: "Al Xin"
date: "12/30/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = F)
```

## Overview

Data from the directory `trn/` will be preprocessed. This will include centering and scaling the data (chemical descriptors will be coerced to a mean of 0 and standard deviation of 1), removal of descriptors with near-zero variance, and removal of molecules with more than 5% missing data. The preprocessed data will be saved in the directory `preprocess/`. Additionally, the settings for preprocessing will be saved in the directory `ad/`, short for applicability domain.

Additionally, the binding affinity, which has been saved in `affinity/clean/` will be merged with the data after processing.

To make the process more clear, preprocessing will only be performed on the `rcdk` descriptors first. The remaining descriptors will be processed later. 
### Running code

Because this step is time-consuming, the default action for the chunks has been set to `eval = F`. If this code needs to be rerun, the code in the chunk `setup` needs to be corrected so that `eval = F` is removed from the default chunk settings.

```{r dir_create}
# Create appropriate directories
desc_name <- c("cdk", "mordred", "ochem", "padel")
pp_dir <- paste0("preprocess/", desc_name) 
ad_dir <- paste0("ad/", desc_name)
if (!dir.exists("preprocess")) dir.create("preprocess")
if (!dir.exists(pp_dir[1])) lapply(pp_dir, dir.create)
if (!dir.exists("ad")) dir.create("ad")
if (!dir.exists(ad_dir[1])) lapply(ad_dir, dir.create)
```

## Dependencies

Data transformations will use the `caret` package. 

```{r dependencies, message = F}
library(caret)
library(qsarr)
library(stringr)
library(dplyr)
```

## Loading data

```{r}
cdk_list <- read_desc_list(
  list.files("trn/cdk", full.names = T), 
  quiet = T
)
```

## Removing activity outliers

Activity outliers are extreme observations of Gibbs free energy. The standard for the cutoff is flexible, as many QSAR methods can handle outliers. For this investigation, the outliers are observations more than 3 standard deviations away from the mean Gibbs free energy change. 

For the CDK descriptors, the data sets all contain less than 5 outliers.

```{r}
cdk_list <- retain_name(
  cdk_list,
  remove_col_outlier,
  col = "dG",
  quiet = F
)
```
## Cleaning NA data

When analyzing descriptors, it is usually easier to handle `NA` values than `NaN` values. The initial step will be to replace `NaN`s with `NA` in the list of data sets. 

```{r}
cdk_list <- retain_name(cdk_list, replace_nan)
```

Additionally, there are certain descriptors that cannot be calculated for a significant number of the chemicals examined. In this case, descriptors that return `NA` for more than 10% of processed molecules will be removed. This boundary is mostly arbitrary. It is based off the intuition that a predictor that is unusable for a tenth of molecules would be unhelpful in model building.

```{r}
cdk_list <- retain_name(
  cdk_list, 
  remove_col_na, 
  threshold = 0.1, 
  quiet = F
)
```

## Removing structure outliers

### Basic preprocessing

The standard preprocessing steps to consider would be removing variables with near zero variance, centering the data, and scaling the data. Removing variable with near zero variance can be accomplished with `qsarr:remove_zerovar`. Centering and scaling is bundled together in the function `qsarr::center_scale`.

Compared to removing based on `NA` proportion, many more variables are removed due to near-zero variance. The number of columns removed ranges from around 80 to 110 out of around 210 predictors. Because the data mostly suffers from potential overfitting (many more predictors than observations), the frequency cutoff for near zero variance is lower than the default (the default is `freqCut = 95/5`).

When centering and scaling, the `"ad"` object is returned for use with applicability domain analysis on external validation data later.

```{r center_scale_zero}
# Columns that are not predictors
non_pred <- c("guest", "dG")

# tst <- remove_zerovar(cdk_list[[2]], ignore_col = non_pred, quiet = F)

cdk_list <- retain_name(
  cdk_list, 
  remove_zerovar, 
  ignore_col = non_pred, 
  quiet = F, 
  freqCut = 90/10
  )

cdk_list_ad <- retain_name(
  cdk_list, 
  center_scale, 
  ignore_col = non_pred, 
  return_ad = T
)

cdk_list <- retain_name(cdk_list_ad, function(x) x$df)
cdk_ad <- retain_name(cdk_list_ad, function(x) x$ad)
```

### Standard deviation method of AD

After these steps are accomplished, structural outliers can be removed. The method used here is derived from a 2015 paper from Roy, Kar, and Ambure.[^1] The method is used in the method `predict.ad`.[^2] 

```{r remove_xoutlier}
cdk_list <- retain_name(
  cdk_list, 
  remove_xoutlier, 
  ignore_col = non_pred, 
  quiet = F
)
```

## Saving data

The preprocessed data will be saved in `preprocess/cdk/`.

The `"ad"` objects will be saved later, grouped along with the other descriptor sources.

```{r}
cdk_save <- sapply(
  names(cdk_list), 
  function(x) {
    pp_dir <- paste0("preprocess/cdk/", x, ".RDS")
    saveRDS(cdk_list[[x]], pp_dir)
  }
)
```

## Repeat above for all data

The above steps for preprocessing can now be repeated on the other three descriptor sources: Mordred, OCHEM, and PaDEL-Descriptor. 

```{r}
# reading all the  non-cdk files
trn_list <- lapply(
  paste0("trn/", c("mordred", "ochem", "padel")), 
  function(x) {
    fnames <- list.files(x, full.names = T)
    read_desc_list(fnames, quiet = T)
  }
)
  
# renaming names to be descriptor specific
trn_list <- Map(
  function(df_list, desc_name) {
    names(df_list) <- paste0(desc_name, "/", names(df_list))
    df_list
  }, 
  df_list = trn_list, 
  desc_name = c("mordred", "ochem", "padel")
) %>%
  unlist(recursive = F)

# Clean NAs
# Remove Y-outliers
pp_list <- retain_name(trn_list, replace_nan) %>%
  retain_name(., remove_col_na) %>%
  retain_name(
    ., 
    remove_col_outlier, 
    col = "dG"
  )

# Center, scale, and remove variable w/ near-zero variance
pp_list <- retain_name(
  pp_list, 
  remove_zerovar, 
  ignore_col = non_pred, 
  freqCut = 90/10
)

pp_list_ad <- retain_name(
  pp_list, 
  center_scale, 
  ignore_col = non_pred, 
  return_ad = T
)

pp_list <- retain_name(pp_list_ad, function(x) x$df)
pp_ad <- retain_name(pp_list_ad, function(x) x$ad)

# Remove X-outlier
pp_list <- retain_name(
  pp_list, 
  remove_xoutlier, 
  ignore_col = non_pred, 
  quiet = F
)

# Save files
pp_save <- sapply(
  names(pp_list), 
  function(x) {
    pp_dir <- paste0("preprocess/", x, ".RDS")
    saveRDS(pp_list[[x]], pp_dir)
  }
)

```

## Applicability domain

The settings for preprocessing used on the training set  will be important in preprocessing future data (the external validation set). They will be saved in `ad/` with the same directory organization as `preprocess/`.

```{r}
# reading all files
ad_list <- list(cdk_ad, pp_ad) %>% 
  unlist(recursive = F) %>%
  setNames(
    paste0(
      sapply(desc_name, rep, length(cdk_ad)), 
      "/", names(cdk_ad)
    )
  )

# Saving applicability domain objects
ad_save <- sapply(
  names(ad_list), 
  function(x) {
    ad_dir <- paste0("ad/", x, ".RDS")
    saveRDS(ad_list[[x]], ad_dir)
  }
)
```

## Preprocessing external validation data

```{r}
desc_name <- c("cdk", "mordred", "ochem", "padel")
data_name <- str_remove(list.files("desc/cdk"), "\\.RDS$")
evpp_dir <- paste0("extval_pp/", desc_name)
ev_dir <- paste0("extval/", desc_name)
if (!dir.exists("extval_pp")) dir.create("extval_pp")
if (!dir.exists(ev_dir[1])) lapply(evpp_dir, dir.create)
```

### Determining molecules outside applicability domain

To simulate the process of applying models, the applicability domain objects and
external validation sets are read from the appropriate directories. 

Though molecules outside of the applicability domain can be removed with
`qsarr::remove_ad()`, they will be retained in this case to evaluate model 
performance. The results of the applicability domain analysis will be saved as
a boolean column `in_ad`.

```{r}
ad_list <- lapply(
  ad_dir, 
  function(x) {
    ad_sublist <- lapply(
      list.files(x, full.names = T), 
      readRDS
    ) %>%
      setNames(nm = data_name)
  }
) %>%
  setNames(nm = desc_name)

ev_list <- lapply(
  ev_dir, 
  function(x) {
    ev_sublist <- lapply(
      list.files(x, full.names = T), 
      readRDS
    ) %>%
      setNames(nm = data_name)
  }
) %>%
  setNames(nm = desc_name)

evpp_list <- lapply(
  desc_name, 
  function(x) {
    ad_sublist <- ad_list[[x]]
    ev_sublist <- ev_list[[x]]
    lapply(
      data_name, 
      function(y) {
        mutate(
          ev_sublist[[y]], 
          in_ad = predict(ad_sublist[[y]], ev_sublist[[y]])
        )
      }
    ) %>%
      setNames(data_name)
  }
) %>% 
  setNames(desc_name)
```

After creating the boolean column for the applicability domain, the data can be
centered and scaled with the applicability domain objects. Because the objects
were created after removing variables with near zero variance, this step also
implicitly removes low-variance variables as well.

```{r}
evpp_list <- lapply(
  desc_name, 
  function(x) {
    ad_sublist <- ad_list[[x]]
    ev_sublist <- evpp_list[[x]]
    lapply(
      data_name, 
      function(y) {
        center_scale(
          df = ev_sublist[[y]], 
          ignore_col = c("guest", "dG", "in_ad"), 
          return_ad = F, 
          ad_obj = ad_sublist[[y]]
        )
      }
    ) %>%
      setNames(data_name)
  }
) %>% 
  setNames(desc_name)
```

The data in the above list can then be saved in the directory using the same 
naming convention as before.

```{r ev_save}
evpp_list <- evpp_list %>% 
  unlist(recursive = F) %>%
  setNames(
    paste0(
      sapply(desc_name, rep, length(data_name)), 
      "/", data_name
    )
  )

evpp_save <- sapply(
  names(evpp_list), 
  function(x) {
    saveRDS(evpp_list[[x]], paste0("extval_pp/", x, ".RDS"))
  }
)
```


```{r}
predict.ad <- function(ad, df, msg = F, ...) {
  if (!is.na(ad$ignore_col[1])) {
    ignore_index <- which(names(df) %in% ad$ignore_col)
    if (length(ignore_index)) df <- df[, -ignore_index]
  }

  if (msg) {
    if (ncol(df) > length(ad$x_mean)) {
      message(
        "There are ", ncol(df) - length(ad$x_mean), " more predictors ",
        "in the data frame compared to the applicability domain"
      )
    }
  }

  # Slightly different that previous error check
  # If predictors in the ad object are not present in the data frame, this is a
  # critical issue that prevents evaluation of the applicability domain
  if (sum(names(ad$x_mean) %in% names(df)) < length(ad$x_mean)) {
    message(
      "Predictors in the applicability domain are missing from the data", "\n",
      "Prediction cannot proceed; exiting with NA"
    )
    return(NA)
  }

  std_df <- lapply(
    names(ad$x_mean),
    function(x) {
      x_mean <- ad$x_mean[x]
      x_sd <- ad$x_sd[x]
      abs(df[, x] - x_mean) / x_sd
    }
  ) %>%
    data.frame()

  # Apply a function rowwise
  # returns T if inside domain
  sapply(
    1:nrow(std_df),
    function(x) {
      x <- std_df[x, ] %>% as.numeric()
      if (min(x, na.rm = T) > 3) F
      if (max(x, na.rm = T) < 3) T
      s_new <- mean(x, na.rm = T) + 1.28 * sd_pop(x)
      ifelse(s_new < 3, T, F)
    }
  )
}

center_scale <-
  function(df,
           ignore_col = NA,
           return_ad = F,
           ad_obj = NA,
           quiet = T,
           ...) {
  if (!is.na(ignore_col[1])) {
    ignore_index <- which(names(df) %in% ignore_col)
    df_retain <- df[, ignore_index]
    df <- df[, -ignore_index]
  }

  # Centering and scaling
  # Uses an applicability domain object with `ad()`
  if (is.na(ad_obj)[1]) {
    ad_obj <- ad(df, ignore_col = ignore_col)
  }


  if (!quiet) {
    if (ncol(df) > length(ad_obj$x_mean)) {
      message(
        "There are ", ncol(df) - length(ad_obj$x_mean), " more predictors ",
        "in the data frame compared to the applicability domain", "\n",
        "Consider ignoring columns with `ignore_col =`", "\n",
        "Only retaining predictors specified in applicability domain"
      )
    }
  }

  # Slightly different that previous error check
  # If predictors in the ad object are not present in the data frame, this is a
  # critical issue that prevents evaluation of the applicability domain
  if (sum(names(ad_obj$x_mean) %in% names(df)) < length(ad_obj$x_mean)) {
    message(
      "Predictors in the applicability domain are missing from the data", "\n",
      "Prediction cannot proceed; exiting with NA"
    )
    return(NA)
  }
    
  cs_df <- lapply(
    names(ad_obj$x_mean),
    function(x) (df[, x] - ad_obj$x_mean[x]) / ad_obj$x_sd[x]
    ) %>%
    data.frame() %>%
    setNames(names(ad_obj$x_mean))

  # replace all NAs with the mean (0)
  cs_df <- lapply(
    cs_df,
    function(x) {
      x[is.na(x)] <- 0
      x
    }
  ) %>%
    data.frame()

  if (return_ad) {
    list(
      df = data.frame(df_retain, cs_df),
      ad = ad_obj
    )
  } else {
    data.frame(df_retain, cs_df)
  }
}

```



[^1]: Kunal roy, Supratik Kar, Pravin Ambure (2015). Chemocetrics and Intelligent Laboratory Systems, https://doi.org/10.1016/j.chemolab.2015.04.013
[^2]: `"ad"` is short for applicability domain. This is an S3 class defined in `qsarr`. The method `predict.ad` returns a boolean vector on whether molecules (rows) are in the domain as defined by the `"ad"` class. 