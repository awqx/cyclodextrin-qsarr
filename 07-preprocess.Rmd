---
title: "06. Preprocessing chemical descriptors"
author: "Al Xin"
date: "12/30/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

Data from the directory `trn/` will be preprocessed. This will include centering and scaling the data (chemical descriptors will be coerced to a mean of 0 and standard deviation of 1), removal of descriptors with near-zero variance, and removal of molecules with more than 5% missing data. The preprocessed data will be saved in the directory `preprocess/`. Additionally, the settings for preprocessing will be saved in the directory `ad/`, short for applicability domain.

Additionally, the binding affinity, which has been saved in `affinity/clean/` will be merged with the data after processing.

To make the process more clear, preprocessing will only be performed on the `rcdk` descriptors first. The remaining descriptors will be processed later. 

```{r dir_create}
# Create appropriate directories
pp_dir <- paste0("preprocess/", list.files("desc", include.dirs = T)) 
ad_dir <- paste0("ad/", list.files("desc", include.dirs = T))
if (!dir.exists("preprocess")) dir.create("preprocess")
if (!dir.exists(pp_dir[1])) lapply(pp_dir, dir.create)
if (!dir.exists("ad")) dir.create("ad")
if (!dir.exists(ad_dir[1])) lapply(ad_dir, dir.create)
```

## Dependencies

Data transformations will use the `caret` package. 

```{r dependencies, message = F}
library(caret)
library(qsarr)
library(stringr)
library(dplyr)
```

## Loading data

```{r}
cdk_list <- read_desc_list(
  list.files("trn/cdk", full.names = T), 
  quiet = T
)
```

## Removing activity outliers

Activity outliers are extreme observations of Gibbs free energy. The standard for the cutoff is flexible, as many QSAR methods can handle outliers. For this investigation, the outliers are observations more than 3 standard deviations away from the mean Gibbs free energy change. 

For the CDK descriptors, the data sets all contain less than 5 outliers.

```{r}
cdk_list <- retain_name(
  cdk_list,
  remove_col_outlier,
  col = "dG",
  quiet = F
)
```
## Cleaning NA data

When analyzing descriptors, it is usually easier to handle `NA` values than `NaN` values. The initial step will be to replace `NaN`s with `NA` in the list of data sets. 

```{r}
cdk_list <- retain_name(cdk_list, replace_nan)
```

Additionally, there are certain descriptors that cannot be calculated for a significant number of the chemicals examined. In this case, descriptors that return `NA` for more than 10% of processed molecules will be removed. This boundary is mostly arbitrary. It is based off the intuition that a predictor that is unusable for a tenth of molecules would be unhelpful in model building.

```{r}
cdk_list <- retain_name(
  cdk_list, 
  remove_col_na, 
  threshold = 0.1, 
  quiet = F
)
```

## Removing structure outliers

### Basic preprocessing

The standard preprocessing steps to consider would be removing variables with near zero variance, centering the data, and scaling the data. Removing variable with near zero variance can be accomplished with `qsarr:remove_zerovar`. Centering and scaling is bundled together in the function `qsarr::center_scale`.

Compared to removing based on `NA` proportion, many more variables are removed due to near-zero variance. The number of columns removed ranges from around 80 to 110 out of around 210 predictors. Because the data mostly suffers from potential overfitting (many more predictors than observations), the frequency cutoff for near zero variance is lower than the default (the default is `freqCut = 95/5`).

When centering and scaling, the `"ad"` object is returned for use with applicability domain analysis on external validation data later.

```{r center_scale_zero}
# Columns that are not predictors
non_pred <- c("guest", "dG")

# tst <- remove_zerovar(cdk_list[[2]], ignore_col = non_pred, quiet = F)

cdk_list <- retain_name(
  cdk_list, 
  remove_zerovar, 
  ignore_col = non_pred, 
  quiet = F, 
  freqCut = 90/10
  )

cdk_list_ad <- retain_name(
  cdk_list, 
  center_scale, 
  ignore_col = non_pred, 
  return_ad = T
)

cdk_list <- retain_name(cdk_list_ad, function(x) x$df)
cdk_ad <- retain_name(cdk_list_ad, function(x) x$ad)
```

### Standard deviation method of AD

After these steps are accomplished, structural outliers can be removed. The method used here is derived from a 2015 paper from Roy, Kar, and Ambure.[^1] The method is used in the method `predict.ad`.[^2] 

```{r remove_xoutlier}
cdk_list <- retain_name(
  cdk_list, 
  remove_xoutlier, 
  ignore_col = non_pred, 
  quiet = F
)
```

## Saving data

```{r}
cdk_save <- sapply(
  names(cdk_list), 
  function(x) {
    pp_dir <- paste0("preprocess/cdk/", x, ".RDS")
    saveRDS(cdk_list[[x]], pp_dir)
  }
)
```

## Repeat above for all data

```{r}
# reading all the  non-cdk files
trn_list <- lapply(
  paste0("trn/", c("mordred", "ochem", "padel")), 
  function(x) {
    fnames <- list.files(x, full.names = T)
    read_desc_list(fnames, quiet = T)
  }
)
  
# renaming names to be descriptor specific
trn_list <- Map(
  function(df_list, desc_name) {
    names(df_list) <- paste0(desc_name, "/", names(df_list))
    df_list
  }, 
  df_list = trn_list, 
  desc_name = c("mordred", "ochem", "padel")
) %>%
  unlist(recursive = F)

# Clean NAs
# Remove Y-outliers
pp_list <- retain_name(trn_list, replace_nan) %>%
  retain_name(., remove_col_na) %>%
  retain_name(
    ., 
    remove_col_outlier, 
    col = "dG"
  )

# Center, scale, and remove variable w/ near-zero variance
pp_list <- retain_name(
  pp_list, 
  remove_zerovar, 
  ignore_col = non_pred, 
  freqCut = 90/10
)

pp_list_ad <- retain_name(
  pp_list, 
  center_scale, 
  ignore_col = non_pred, 
  return_ad = T
)

pp_list <- retain_name(pp_list_ad, function(x) x$df)
pp_ad <- retain_name(pp_list_ad, function(x) x$ad)

# Remove X-outlier
pp_list <- retain_name(
  pp_list, 
  remove_xoutlier, 
  ignore_col = non_pred, 
  quiet = F
)

# Save files
pp_save <- sapply(
  names(pp_list), 
  function(x) {
    pp_dir <- paste0("preprocess/", x, ".RDS")
    saveRDS(pp_list[[x]], pp_dir)
  }
)

```

## Applicability domain

The settings for preprocessing used on the training set  will be important in preprocessing future data (the external validation set).

```{r}
# reading all files
desc_list <- lapply(
  paste0("trn/", c("cdk", "mordred", "ochem", "padel")), 
  function(x) {
    fnames <- list.files(x, full.names = T)
    read_desc_list(fnames, quiet = T)
  }
)

# renaming to be descriptor specific
# doing initial cleaning
desc_list <- Map(
  function(df_list, desc_name) {
    names(df_list) <- paste0(desc_name, "/", names(df_list))
    df_list
  }, 
  df_list = desc_list, 
  desc_name = c("cdk", "mordred", "ochem", "padel")
) %>%
  unlist(recursive = F)

desc_list <- retain_name(desc_list, replace_nan) %>%
  retain_name(., remove_col_na) %>%
  retain_name(., remove_col_outlier, col = "dG")

# Getting variables without near-zero variance
# This step is admittedly

ad_list <- retain_name(desc_list, ad, ignore_col = non_pred)

# Saving applicability domain objects
ad_save <- sapply(
  names(ad_list), 
  function(x) {
    ad_dir <- paste0("ad/", x, ".RDS")
    saveRDS(ad_list[[x]], ad_dir)
  }
)
```


[^1]: Kunal roy, Supratik Kar, Pravin Ambure (2015). Chemocetrics and Intelligent Laboratory Systems, https://doi.org/10.1016/j.chemolab.2015.04.013
[^2]: `"ad"` is short for applicability domain. This is an S3 class defined in `qsarr`. The method `predict.ad` returns a boolean vector on whether molecules (rows) are in the domain as defined by the `"ad"` class. 